# 工作流程
爬行和抓取
- 蜘蛛：robots.txt
- 跟踪链接：广度优先/深度优先
- 吸引蜘蛛：网站和页面权重；页面更新频率；导入链接(```<a>```标签？)；与首页点击距离；URL结构（短的、层次浅的URL可能被认为权重较高）
- 地址库：蜘蛛发现链接后并不是马上访问，而是将URL存入地址库，然后统一安排抓取
- 复制内容检测：有些蜘蛛在爬取内容时会进行检测，如果发现是低权重的网站上复制、转载的内容，往往会停止爬取；